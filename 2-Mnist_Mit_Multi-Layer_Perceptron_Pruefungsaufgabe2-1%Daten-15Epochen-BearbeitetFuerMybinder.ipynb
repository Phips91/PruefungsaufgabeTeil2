{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://akademie.datamics.com/kursliste/\">![title](bg_datamics_top.png)</a>\n",
    "\n",
    "<center><em>© Datamics</em></center><br><center><em>Besuche uns für mehr Informationen auf <a href='https://akademie.datamics.com/kursliste/'>www.akademie.datamics.com</a></em></center>\n",
    "\n",
    "# MNIST mit Multi-Layer Perceptron\n",
    "\n",
    "In dieser Lektion werden wir ein Multi Layer Perceptron Modell erstellen und versuchen damit handgeschriebenen Zahlen zu klassifizieren. Das ist ein sehr verbreitetes Einsteigerproblem für Tensorflow.\n",
    "\n",
    "Denkt daran, dass eine einzige Lektion niemals ausreichen wird, um Deep Learning und/oder Tensorflow in seiner Komlexität abzudecken!\n",
    "\n",
    "## Die Daten laden\n",
    "\n",
    "Wir werden die berühmten MNIST Daten über [handgeschriebenen Zahlen](http://yann.lecun.com/exdb/mnist/) verwenden.\n",
    "\n",
    "Die Bilder die wir verwenden werden sind schwarz-weiß Bilder der größe 28 x 28, d.h. 784 Pixel insgesamt. Unsere Features werden die Pixelwerte für jeden Pixel sein. Entweder ist der Pixel \"weiß\" (also eine 0 in den Daten) oder er hat einen Pixelwert.\n",
    "\n",
    "Wir werden versuchen korrekt vorherzusagen, welche Nummer geschrieben steht. Dazu verwenden wir lediglich die Bilddaten in Form unseres Arrays. Diese Art von Problem (Image Recognition oder auf Deutsch: Bilderkennung) ist ein tolle Use Case für Deep Learning Methoden!\n",
    "\n",
    "Die Daten sind für Deep Learning das, was der Iris Datensatz für typische Machine Learning Algorithmen ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import von Bibliotheken in Python.\n",
    "\n",
    "In diesem Code werden die Python-Bibliotheken TensorFlow, NumPy, Logging, Time, Matplotlib und Unittest importiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Code importiert verschiedene Python-Bibliotheken, lädt den MNIST-Datensatz, normalisiert die Daten, teilt sie in Trainings- und Testdaten auf und konvertiert die Trainingsdaten in das gewünschte Datenformat für spätere Verwendung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "import unittest\n",
    "from functools import wraps\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Pfad zu den heruntergeladenen MNIST-Daten\n",
    "train_data_path = 'train-images.idx3-ubyte'\n",
    "test_data_path = 't10k-images.idx3-ubyte'\n",
    "train_labels_path = 'train-labels.idx1-ubyte'  # Hinzugefügt\n",
    "test_labels_path = 't10k-labels.idx1-ubyte'  # Hinzugefügt\n",
    "\n",
    "# Laden der MNIST-Daten aus den lokal gespeicherten Dateien\n",
    "def load_mnist_data(data_path):\n",
    "    with open(data_path, 'rb') as f:\n",
    "        magic, num_images, num_rows, num_cols = struct.unpack('>IIII', f.read(16))\n",
    "        images = np.fromfile(f, dtype=np.uint8).reshape(num_images, num_rows, num_cols)\n",
    "    return images\n",
    "\n",
    "# Laden der MNIST-Label aus den lokal gespeicherten Dateien (Hinzugefügt)\n",
    "def load_mnist_labels(labels_path):\n",
    "    with open(labels_path, 'rb') as f:\n",
    "        magic, num_labels = struct.unpack('>II', f.read(8))\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "# Laden Sie die MNIST-Trainings- und Testdaten\n",
    "x_train_mnist = load_mnist_data(train_data_path)\n",
    "x_test_mnist = load_mnist_data(test_data_path)\n",
    "# Laden Sie die MNIST-Label\n",
    "train_labels = load_mnist_labels(train_labels_path)\n",
    "test_labels = load_mnist_labels(test_labels_path)\n",
    "\n",
    "# Normalisieren der Daten\n",
    "class Normalize(object):\n",
    "    def normalize(self, X_train, X_test):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        # Umformen in 2D-Arrays (Flatten)\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_test = self.scaler.transform(X_test)\n",
    "        return (X_train, X_test)\n",
    "\n",
    "    def inverse(self, X_train, X_test):\n",
    "        X_train = self.scaler.inverse_transform(X_train)\n",
    "        X_test = self.scaler.inverse_transform(X_test)\n",
    "        return (X_train, X_test)\n",
    "\n",
    "# Aufteilen der Daten\n",
    "def split(X, y, splitRatio):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - splitRatio, random_state=42)\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Annahme: Sie haben bereits die MNIST-Trainings- und Testdaten geladen und in x_train_mnist und x_test_mnist gespeichert.\n",
    "\n",
    "# Normalisieren der Daten\n",
    "normalizer = Normalize()\n",
    "x_train, x_test = normalizer.normalize(x_train_mnist, x_test_mnist)\n",
    "\n",
    "# Aufteilen der Daten\n",
    "splitRatio = 0.8  # Ändern Sie den Split-Verhältnis nach Bedarf\n",
    "x_train, y_train, x_test, y_test = split(x_train, train_labels, splitRatio)\n",
    "\n",
    "# Stellen Sie sicher, dass die Daten korrekt geladen wurden (ersetzen Sie y durch die entsprechenden Label-Daten)\n",
    "assert x_train.shape == (int(0.8 * len(x_train_mnist)), x_train_mnist.shape[1] * x_train_mnist.shape[2])\n",
    "assert x_test.shape == (int(0.2 * len(x_train_mnist)), x_train_mnist.shape[1] * x_train_mnist.shape[2])\n",
    "assert y_train.shape == (int(0.8 * len(x_train_mnist)),)\n",
    "assert y_test.shape == (int(0.2 * len(x_train_mnist)),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definieren der my_logger und my_timer Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def my_logger(orig_func):\n",
    "    logging.basicConfig(filename='{}.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logging.info(\n",
    "            'Ran with args: {}, and kwargs: {}'.format(args, kwargs))\n",
    "        return orig_func(*args, **kwargs)\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_logger(orig_func):\n",
    "    logging.basicConfig(filename='{}.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "    \n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logging.info(\n",
    "            'Ran with args: {}, and kwargs: {}'.format(args, kwargs))\n",
    "        return orig_func(*args, **kwargs)\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def my_timer(orig_func):\n",
    "    import time\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t1 = time.time()\n",
    "        result = orig_func(*args, **kwargs)\n",
    "        t2 = time.time() - t1\n",
    "        print('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_timer(orig_func):\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t1 = time.time()\n",
    "        result = orig_func(*args, **kwargs)\n",
    "        t2 = time.time() - t1\n",
    "        print('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Code wird eine Python-Klasse mit dem Namen \"TheAlgorithm\" definiert, die verschiedene Methoden wie den Konstruktor __init__, die Methode fit und die Methode predict enthält, wobei die Dekoratoren @my_logger und @my_timer verwendet werden, um die Ausführung dieser Methoden zu protokollieren und die Zeitmessung durchzuführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheAlgorithm(object):\n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train, self.y_train, self.X_test, self.y_test = X_train, y_train, X_test, y_test\n",
    "\n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def fit(self):\n",
    "        x_train, y_train, x_test, y_test = self.X_train, self.y_train, self.X_test, self.y_test\n",
    "\n",
    "        normalizer = Normalize()  # Use the correct class name here\n",
    "        x_train, x_test = normalizer.normalize(x_train, x_test)\n",
    "\n",
    "        train_samples = x_train.shape[0]\n",
    "\n",
    "        self.classifier = LogisticRegression(\n",
    "            C=50. / train_samples,\n",
    "            multi_class='multinomial',\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            tol=0.1,\n",
    "            class_weight='balanced',\n",
    "        )\n",
    "\n",
    "        self.classifier.fit(x_train, y_train)\n",
    "        self.train_predictions = self.classifier.predict(x_train)\n",
    "        self.train_accuracy = np.mean(self.train_predictions.ravel() == y_train.ravel()) * 100\n",
    "        self.train_confusion_matrix = confusion_matrix(y_train, self.train_predictions)\n",
    "        return self.train_accuracy\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"Evaluates the model on the given dataset.\n",
    "\n",
    "        Args:\n",
    "            X: The data to evaluate the model on.\n",
    "            y: The labels for the data.\n",
    "\n",
    "        Returns:\n",
    "            The accuracy of the model on the given dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        # Make predictions on the data\n",
    "        predictions = self.predict(X)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        accuracy = np.mean(predictions == y)\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def predict(self):\n",
    "        x_test = self.X_test  # Test data doesn't need to be normalized again\n",
    "\n",
    "        self.test_predictions = self.classifier.predict(x_test)\n",
    "        self.test_accuracy = np.mean(self.test_predictions.ravel() == self.y_test.ravel()) * 100\n",
    "        self.test_confusion_matrix = confusion_matrix(self.y_test, self.test_predictions)\n",
    "        self.report = classification_report(self.y_test, self.test_predictions)\n",
    "        print(\"Classification Report for the classifier:\\n%s\\n\" % (self.report))\n",
    "\n",
    "        return self.test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten Format\n",
    "\n",
    "Die Daten sind im Vektor Format gespeichert, obwohl die Originaldaten eine 2-dimensionale Matrix waren, die angab, wie viele Pigmente sich an welcher Position befinden. Untersuchen wir das genauer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = x_train[2].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22b1ab13dd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter\n",
    "\n",
    "Wir werden 4 Parameter definieren müssen. Es ist wirklich (wirklich) schwer gute Parameterwerte für einen Datensatz zu bestimmen, mit dem man keine Erfahrung hat. Da dieser MNIST Datensatz allerdings so berühmt ist haben wir schon einige Ausgangswerte. Die Parameter sind:\n",
    "\n",
    "* Learning Rate - Wie schnell die Kostenfunktion angepasst wird\n",
    "* Traing Epochs - Wie viele Trainingszyklen durchlaufen werden sollen\n",
    "* Batch Size - Größe der \"Batches\" an Traingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "learning_rate = 0.001\n",
    "training_epochs = 2\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netzwerk Parameter\n",
    "\n",
    "Hier haben wir Parameter welche unser Neuronales Netz direkt definieren. Diese werden entsprechend der betrachteten Daten angepasst und hängen auch davon ab, welche Art von Netz man nutzt. Es sind bis zu diesem Punkt erst einmal nur Zahlen, die wir später verwenden, um unser Netz zu definieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netzwerk Parameter\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "n_input = x_train.shape[1]\n",
    "n_classes = 10\n",
    "n_samples = len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.Input(shape=(n_input,), dtype=tf.float32)\n",
    "y = tf.keras.Input(shape=(n_classes,), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLayer Modell\n",
    "\n",
    "Es ist Zeit unser Modell zu erstellen. Wiederholen wir deshalb kurz, was wir erstellen wollen:\n",
    "\n",
    "Zuerst erhalten wir einen *Input* in Form eines Datenarrays und schicken diesen an die erste *Hidden Layer*. Dann wird den Daten ein  *Weight* zwischen den Schichten zugewiesen (welches zuerst ein zufälliger Wert ist). Anschließend wird es an einen *Node* geschicht und unterläuft eine *Activation Function* (zusammen mit einem Bias, wie in der Neural Network Lektion erwähnt). Dann geht es weiter zur nächsten *Layer* und immer so weiter, bis zur finalen *Output Layer*. In unserem Fall werden wir nur 2 *Hidden Layers* verwenden. Je mehr wir davon verwenden, desto länger braucht das Modell (aber er hat mehr Möglichkeiten um die Genauigkeit zu erhöhen).\n",
    "\n",
    "Sobald die transformierte Daten die *Output Layer* erreicht haben müssen wir sie auswerten. Hier verwenden wir eine *Loss Function* (auch Cost Function genannt). Diese berechnet, wie sehr wir vom gewünschten Ergebnis entfernt sind. In diesem Fall: Wie viele der Klassen wir richtig zugeteilt haben.\n",
    "\n",
    "Dann wenden wir eine Optimierungsfunktion an, um die *Costs* (bzw. den Error) zu minimieren. Dies geschiet durch die Anpassung der *Weights* entlang des Netzes. Wir verwenden in unserem Beispiel den [Adam Optimizer](https://arxiv.org/pdf/1412.6980v8.pdf), welcher eine (im Vergleich zu anderen) sehr neue Entwicklung ist.\n",
    "\n",
    "Wir können anpassen, wie schnell diese Optimierung angewendet wird, indem wir unseren *Learning Rate* Parameter anpassen. Je geringer die Rate, desto höher die Möglichkeiten für Anpassungen. Dies erzeugt allerdings die Kosten einer erhöhten Wartezeit. Ab einem bestimmten Punkt lohnt es sich nicht mehr, die Learning Rate weiter zu senken.\n",
    "\n",
    "Jetzt können wir unser Modell erstellen. Wir beginnen mit 2 Hidden Layers, welche die []() Activation Function verwenden. Dies ist eine einfache Umformungsfunktion, die entweder x oder 0 zurückgibt. Für unsere finale Output Layer verwenden wir eine lineare Activation mit Matrixmultiplikation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Code wird eine Funktion namens \"multilayer_perceptron\" definiert, die ein mehrschichtiges neuronales Netzwerk mit ReLU-Aktivierungsfunktionen für die Hidden Layers und linearer Aktivierungsfunktion für die Output Layer erstellt und die Ausgabe des Netzwerks zurückgibt, wobei die Funktionen `my_logger` und `my_timer` als Dekoratoren verwendet werden, um die Ausführung der Funktion zu protokollieren und die Zeitmessung durchzuführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@my_logger\n",
    "@my_timer\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : Platzhalter für den Dateninput\n",
    "    weights: Dictionary der Weights\n",
    "    biases: Dictionary Der Biases\n",
    "    '''\n",
    "    \n",
    "    # Erste Hidden layer mit RELU Activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Zweite Hidden layer mit RELU Activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Letzte Output layer mit linearer Activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights und Bias\n",
    "\n",
    "Damit unser Tensorflow Modell funktioniert müssen wir zwei Dictionaries anlegen, die unsere Weights und Biases enthalten. Wir können das `tf.variable` Objekt verwenden. Dies ist anders als eine Konstante, da Tensorflow's Graph Objekt alle Zustände der Variablen wahrnimmt. Eine Variable ist ein anpassbares Tensor, der zwischen Tensorflow's Graph von interagierenden Operationen lebt. Er kann durch die Berechnung verwendet und verändert werden. Wir werden die Modell Parameter generell als Variablen verwenden. Aus der Dokumentation können wir entnehmen:\n",
    "\n",
    "    A variable maintains state in the graph across calls to `run()`. You add a variable to the graph by constructing an instance of the class `Variable`.\n",
    "\n",
    "    The `Variable()` constructor requires an initial value for the variable, which can be a `Tensor` of any type and shape. The initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods.\n",
    "    \n",
    "Wir werden Tensorflow's eingebaute `random_normal` Methode verwenden, um zufällige Werte für unsere Weights und Biases zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gewichtsinitialisierung\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random.normal([n_input, n_hidden_1], dtype=tf.float32)),\n",
    "    'h2': tf.Variable(tf.random.normal([n_hidden_1, n_hidden_2], dtype=tf.float32)),\n",
    "    'out': tf.Variable(tf.random.normal([n_hidden_2, n_classes], dtype=tf.float32))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias-Initialisierung\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random.normal([n_hidden_1], dtype=tf.float32)),\n",
    "    'b2': tf.Variable(tf.random.normal([n_hidden_2], dtype=tf.float32)),\n",
    "    'out': tf.Variable(tf.random.normal([n_classes], dtype=tf.float32))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(784, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.add), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_1), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(256, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.add_1), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_2), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(256, 10) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(10,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "multilayer_perceptron ran in: 0.03346824645996094 sec\n"
     ]
    }
   ],
   "source": [
    "# Model erstellen\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost und Optimierungs-Funktion\n",
    "\n",
    "Wir verwenden Tensorflow's eingebaute Funktionen für diesesn Teil. Weitere Details bietet die Dokumentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost und Optimierungsfunktion definieren\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits=pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisierung der Variablen\n",
    "\n",
    "Wir initialisieren nun alle tf.Variable Objekte die wir zuvor erstellt haben. Das wird das erste sein, dass wir ausführen, wenn wir unser Modell trainieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Modell trainieren\n",
    "\n",
    "### next_batch()\n",
    "\n",
    "Bevor wir beginnen möchte ich eine weitere nützliche Funktion in unserem MNIST Datenobjekt abdecken, die `next_batch` heißt. Diese gibt ein Tupel in der Form (X,y) mit einem X Array der Daten und einem y Array der Klasse. Zum Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle ein TensorFlow-Dataset aus den Trainingsdaten\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "\n",
    "# Mische die Daten und teile sie in Batches auf\n",
    "batch_size = 1\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
    "\n",
    "# Erstelle einen Iterator für das Dataset\n",
    "train_iterator = iter(train_dataset)\n",
    "\n",
    "# Greife auf ein Batch von Daten zu\n",
    "Xsamp, ysamp = next(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22b2022b7d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wandele Xsamp in ein Numpy-Array um\n",
    "Xsamp_numpy = Xsamp.numpy()\n",
    "\n",
    "# Zeige das Bild mit imshow\n",
    "plt.imshow(Xsamp_numpy.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0], shape=(1,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "print(ysamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ihre Decorators\n",
    "\n",
    "def my_logger(orig_func):\n",
    "    logging.basicConfig(filename='{}.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logging.info(\n",
    "            'Ran with args: {}, and kwargs: {}'.format(args, kwargs))\n",
    "        return orig_func(*args, **kwargs)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "def my_timer(orig_func):\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t1 = time.time()\n",
    "        result = orig_func(*args, **kwargs)\n",
    "        t2 = time.time() - t1\n",
    "        print('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        return result\n",
    "\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Die Session ausführen\n",
    "\n",
    "Jetzt ist es Zeit unsere Session auszuführen! Achte darauf wie wir zwei Schleifen verwenden. Die äußere, die die Epochs durchläuft, und die innere, die die Batches für jede Epoch des Trainings ausführt.\n",
    "\n",
    "## Wichtig, hier wurden aus zeitlichen Gründen mit 1% der Daten gearbeitet. Der Code ist mit jeder Prozentzahl reproduzierbar.\n",
    "\n",
    "Es wurde aus zeitlicher und übersichtlicher Sicht eine View sowie eine Abfrage des gewünschten Prozentsatzes eingebaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geben Sie den Prozentsatz der Daten ein, der verarbeitet werden soll (0-100): 1\n",
      "multilayer_perceptron ran in: 0.01564335823059082 sec\n",
      "multilayer_perceptron ran in: 0.015647411346435547 sec\n",
      "multilayer_perceptron ran in: 0.01563858985900879 sec\n",
      "multilayer_perceptron ran in: 0.01562643051147461 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01564955711364746 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01564931869506836 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01562666893005371 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.006521701812744141 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015626907348632812 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015627145767211914 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015626907348632812 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015625 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015639543533325195 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0019998550415039062 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015626907348632812 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01563882827758789 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015643596649169922 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01563739776611328 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01560664176940918 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01564955711364746 sec\n",
      "multilayer_perceptron ran in: 0.015630006790161133 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015631675720214844 sec\n",
      "multilayer_perceptron ran in: 0.015648603439331055 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015625715255737305 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015610694885253906 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01561284065246582 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015620231628417969 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015625715255737305 sec\n",
      "multilayer_perceptron ran in: 0.015625953674316406 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.006510257720947266 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.006511211395263672 sec\n",
      "multilayer_perceptron ran in: 0.015625476837158203 sec\n",
      "multilayer_perceptron ran in: 0.015625476837158203 sec\n",
      "multilayer_perceptron ran in: 0.015624761581420898 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01562809944152832 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.006510734558105469 sec\n",
      "multilayer_perceptron ran in: 0.015625 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015624761581420898 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0156252384185791 sec\n",
      "multilayer_perceptron ran in: 0.01584649085998535 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "Epoch: 1 Cost=489841.5000\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01563572883605957 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015613555908203125 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01565384864807129 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015624046325683594 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015625476837158203 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015625953674316406 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015639305114746094 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01562666893005371 sec\n",
      "multilayer_perceptron ran in: 0.01562786102294922 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015654802322387695 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01563549041748047 sec\n",
      "multilayer_perceptron ran in: 0.015628337860107422 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015624523162841797 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015613555908203125 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015625953674316406 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01561427116394043 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015612363815307617 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015613317489624023 sec\n",
      "multilayer_perceptron ran in: 0.015622377395629883 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015640735626220703 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.006522178649902344 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015649080276489258 sec\n",
      "multilayer_perceptron ran in: 0.01562666893005371 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015625476837158203 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015642404556274414 sec\n",
      "multilayer_perceptron ran in: 0.015610933303833008 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015627145767211914 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.006506443023681641 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015625715255737305 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015639305114746094 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015624284744262695 sec\n",
      "multilayer_perceptron ran in: 0.015625476837158203 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015628337860107422 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.016663312911987305 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015643596649169922 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015636920928955078 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015636920928955078 sec\n",
      "multilayer_perceptron ran in: 0.015613794326782227 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01561427116394043 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015639543533325195 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.01579737663269043 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0065097808837890625 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015626192092895508 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015624761581420898 sec\n",
      "multilayer_perceptron ran in: 0.015625715255737305 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015641212463378906 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "multilayer_perceptron ran in: 0.015625476837158203 sec\n",
      "multilayer_perceptron ran in: 0.0 sec\n",
      "Epoch: 2 Cost=4302564.5000\n",
      "Modellierung ist beendet: 2 Epochs of Training\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow import keras\n",
    "\n",
    "# Eingabe vom Benutzer: Prozentsatz der Daten, die verarbeitet werden sollen\n",
    "percentage_to_process = float(input(\"Geben Sie den Prozentsatz der Daten ein, der verarbeitet werden soll (0-100): \"))\n",
    "\n",
    "# Berechnen Sie die Anzahl der Datensätze, die verarbeitet werden sollen\n",
    "n_samples_to_process = int(n_samples * (percentage_to_process / 100))\n",
    "\n",
    "# Training Epochs\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.0\n",
    "\n",
    "    total_batch = int(n_samples_to_process / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "\n",
    "        # Den nächsten Batch an Trainingsdaten und -labels nehmen\n",
    "\n",
    "        batch_x = tf.cast(x_train[i * batch_size: (i + 1) * batch_size], tf.float32)\n",
    "        batch_y = tf.cast(y_train[i * batch_size: (i + 1) * batch_size], tf.float32)\n",
    "\n",
    "        # Führen Sie die Optimierung und Cost-Berechnung durch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            pred = multilayer_perceptron(batch_x, weights, biases)\n",
    "\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=batch_y, logits=pred))\n",
    "\n",
    "        gradients = tape.gradient(loss, list(weights.values()) + list(biases.values()))\n",
    "        optimizer.apply_gradients(zip(gradients, list(weights.values()) + list(biases.values())))\n",
    "\n",
    "        avg_cost += loss / total_batch\n",
    "\n",
    "    print(\"Epoch: {} Cost={:.4f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "print(\"Modellierung ist beendet: {} Epochs of Training\".format(training_epochs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell Auswertung\n",
    "\n",
    "Tensorflow bietet einige eingebaute Funktionen, die uns bei der Auswertung helfen. Dazu gehören `tf.equal` und `tf.reduce_mean`.\n",
    "\n",
    "\n",
    "### tf.equal\n",
    "\n",
    "Dies ist im Grunde genommen nur eine Kontrolle, ob die Vorhersagen mit den Labels übereinstimmen. Da wir in unserem Fall wissen, dass die Labels eine 1 in einem Array von Nullen sind, können wir `argmax()` verwenden, um die Position zu vergleichen. Denke daran, dass y immer noch der Platzhalter ist, den wir anfangs erstellt haben. Wir werden eine Reihe an Operationen durchführen, um einen Tensor zu erhalten, in den wir die Testdaten einlesen können, um es auszuwerten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste das Modell\n",
    "correct_predictions = tf.math.reduce_all(tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.bool, name=None), name='tf.math.reduce_all/All:0', description=\"created by layer 'tf.math.reduce_all'\")\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um numerische Werte für unsere Vorhersagen zu erhalten müssen wir `tf.cast` verwenden, um den Tensor mit Booleans zurückzuführen in einen Tensor mit Floats. Dann können wir den Durchschnitt nehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='tf.cast/Cast:0', description=\"created by layer 'tf.cast'\")\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt können wir `tf.reduce_mean` verwenden, um den Durchschnitt der Elemente im Tensor zu erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.keras_tensor.KerasTensor"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das wirkt evtl. etwas merkwürdig, aber diese Genauigkeit ist immer noch ein Tensor Objekt. Denke daran, dass wir immer noch die tatsächlichen Testdaten übergeben müssen. Jetzt können wir die MNIST Testlabels und Bilder aufrufen und die Genauigkeit auswerten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 8, ..., 9, 7, 2], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `eval()` Methode erlaubt es uns direkt in der Session den Tensor auszuwerten ohne `tf.sess():mm` aufrufen zu müssen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keine GPU gefunden. Verwende die CPU.\n",
      "Epoch 1/2\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.2855 - sparse_categorical_accuracy: 0.9186\n",
      "Epoch 2/2\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1076 - sparse_categorical_accuracy: 0.9680\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1025 - sparse_categorical_accuracy: 0.9675\n",
      "Test Loss: 0.1025092676281929\n",
      "Test Accuracy: 0.9674999713897705\n"
     ]
    }
   ],
   "source": [
    "# Überprüfen, ob eine GPU verfügbar ist\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    print(\"GPU gefunden. Aktiviere GPU-Unterstützung.\")\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print(\"Keine GPU gefunden. Verwende die CPU.\")\n",
    "\n",
    "# Erstellen des Modells\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(n_input,)),  \n",
    "    tf.keras.layers.Dense(n_hidden_1, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(n_hidden_2, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(n_classes, activation=None)\n",
    "])\n",
    "\n",
    "# Kompilieren des Modells mit der Genauigkeitsmetrik\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "# Trainieren des Modells auf den Trainingsdaten in Batches mit einer erhöhten Batch-Größe\n",
    "x_train_flattened = x_train.reshape(-1, n_input)\n",
    "batch_size = 128  # Erhöhen Sie die Batch-Größe, um die GPU besser auszulasten\n",
    "model.fit(x_train_flattened, y_train, batch_size=batch_size, epochs=training_epochs)\n",
    "\n",
    "# Evaluieren der Genauigkeit auf den Testdaten (nur am Ende)\n",
    "x_test_flattened = x_test.reshape(-1, n_input)\n",
    "test_loss, test_accuracy = model.evaluate(x_test_flattened, y_test)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisieren des Unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier startet der Unittest, zu anfang werden die Datenausgelesen und anschließend die Train Accuracy und Test Accurracy ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST: (48000, 784) (48000,)\n",
      "__init__ ran in: 0.0 sec\n",
      "fit ran in: 12.123776912689209 sec\n",
      "\n",
      "Train Accuracy: 72.53645833333333 \n",
      "\n",
      "Train confusion matrix:\n",
      "[[3544    5   19   17   25    5  106   22   39    3]\n",
      " [   3 4153   66   28    2   19   19   18   13    0]\n",
      " [ 255  296 2386  106  178   15  413  105   71   36]\n",
      " [ 113  159  172 2834   38  169   64   80  145  116]\n",
      " [  77   88   14   31 2874  201  134   79   42  165]\n",
      " [ 328  136   54  656  276 1429  188  211  105   90]\n",
      " [ 143   61   64   31   98  146 3208   13   29    0]\n",
      " [ 170  123  132   24   99   10   19 3153   30  228]\n",
      " [  60  478  148  429   42  132  218   23 2133  106]\n",
      " [ 122  104   41  175  389  181   81  451  131 2140]]\n",
      "\n",
      "Classification Report for the classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.81       963\n",
      "           1       0.75      0.95      0.84      1099\n",
      "           2       0.77      0.61      0.68       923\n",
      "           3       0.67      0.76      0.71      1022\n",
      "           4       0.72      0.78      0.75       961\n",
      "           5       0.62      0.44      0.51       844\n",
      "           6       0.73      0.85      0.79       948\n",
      "           7       0.75      0.79      0.77       978\n",
      "           8       0.80      0.54      0.65       922\n",
      "           9       0.77      0.59      0.67       940\n",
      "\n",
      "    accuracy                           0.73      9600\n",
      "   macro avg       0.73      0.72      0.72      9600\n",
      "weighted avg       0.73      0.73      0.72      9600\n",
      "\n",
      "\n",
      "predict ran in: 0.04032731056213379 sec\n",
      "\n",
      "Test Accuracy: 73.19791666666666 \n",
      "\n",
      "Test confusion matrix:\n",
      "[[ 891    0    7    3   11    2   33    3   11    2]\n",
      " [   0 1048   25   10    0    5    5    3    3    0]\n",
      " [  77   70  559   18   43    4   95   32   17    8]\n",
      " [  25   42   40  777   11   42   14   17   27   27]\n",
      " [  22   21    6    9  748   61   31   19   11   33]\n",
      " [  81   20   12  169   58  369   40   60   22   13]\n",
      " [  32   16   12   10   30   33  807    3    5    0]\n",
      " [  53   31   30    6   27    1    3  772    4   51]\n",
      " [  14  118   26  111   13   35   60    7  502   36]\n",
      " [  31   26    7   41   93   39   14  112   23  554]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Verwenden Sie die bereits geladenen Daten aus Code1\n",
    "    X = x_train  # Hier die x_train-Matrix verwenden\n",
    "    y = y_train  # Hier die y_train-Matrix verwenden\n",
    "\n",
    "    print('MNIST:', X.shape, y.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - splitRatio, random_state=42)\n",
    "\n",
    "    np.random.seed(31337)\n",
    "\n",
    "    ta = TheAlgorithm(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    train_accuracy = ta.fit()\n",
    "\n",
    "    print()\n",
    "\n",
    "    print('Train Accuracy:', train_accuracy, '\\n')\n",
    "\n",
    "    print(\"Train confusion matrix:\\n%s\\n\" % ta.train_confusion_matrix)\n",
    "\n",
    "    test_accuracy = ta.predict()\n",
    "\n",
    "    print()\n",
    "\n",
    "    print('Test Accuracy:', test_accuracy, '\\n')\n",
    "\n",
    "    print(\"Test confusion matrix:\\n%s\\n\" % ta.test_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung der Unittests ausgeführt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test des Ausfalls der Laufzeit von test_fit mit 0,01% der representativen Zeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "======================================================================\n",
      "ERROR: test_fit (__main__.TestInput.test_fit)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Phili\\AppData\\Local\\Temp\\ipykernel_18488\\173783389.py\", line 34, in test_fit\n",
      "    self.assertEqual(self.ta.score(self.X_train, self.y_train), self.train_accuracy)\n",
      "                                                                ^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'TestInput' object has no attribute 'train_accuracy'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_predict (__main__.TestInput.test_predict)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Phili\\AppData\\Local\\Temp\\ipykernel_18488\\173783389.py\", line 41, in test_predict\n",
      "    self.assertEqual(self.ta.score(self.X_test, self.y_test), self.test_accuracy)\n",
      "                                   ^^^^^^^^^^^\n",
      "AttributeError: 'TestInput' object has no attribute 'X_test'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 485.432s\n",
      "\n",
      "FAILED (errors=2)\n"
     ]
    }
   ],
   "source": [
    "class TestInput(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        pass\n",
    "\n",
    "    def setUp(self):\n",
    "        print('setUp')\n",
    "\n",
    "        # Load the data\n",
    "        x_train_mnist = load_mnist_data('train-images.idx3-ubyte')\n",
    "\n",
    "        # Reshape the data to 2 dimensions\n",
    "        x_train_mnist = np.reshape(x_train_mnist, (x_train_mnist.shape[0], -1))\n",
    "\n",
    "        # Normalize the data\n",
    "        normalizer = MinMaxScaler()\n",
    "        x_train_mnist = normalizer.fit_transform(x_train_mnist)\n",
    "\n",
    "        self.X_train = x_train_mnist\n",
    "\n",
    "        self.y_train = load_mnist_labels('train-labels.idx1-ubyte')\n",
    "\n",
    "    def tearDown(self):\n",
    "        pass\n",
    "\n",
    "    def test_fit(self):\n",
    "        np.random.seed(31337)\n",
    "        self.ta = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "        self.ta.fit(self.X_train, self.y_train)\n",
    "        self.assertEqual(self.ta.score(self.X_train, self.y_train), self.train_accuracy)\n",
    "        self.assertTrue(np.array_equal(self.ta.predict_proba(self.X_train), self.train_confusion_matrix.astype('float')))\n",
    "\n",
    "    def test_predict(self):\n",
    "        np.random.seed(31337)\n",
    "        self.ta = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "        self.ta.fit(self.X_train, self.y_train)\n",
    "        self.assertEqual(self.ta.score(self.X_test, self.y_test), self.test_accuracy)\n",
    "        self.assertTrue(np.array_equal(self.ta.predict_proba(self.X_test), self.test_confusion_matrix.astype('float')))\n",
    "\n",
    "    def test_runtime_fit(self):\n",
    "        np.random.seed(31337)\n",
    "        self.ta = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "        # Messen der Laufzeit der fit-Funktion\n",
    "        start_time = time.time()\n",
    "        self.ta.fit(self.X_train, self.y_train)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        # Legen Sie den Grenzwert fest, z.B. 120% der repräsentativen Laufzeit\n",
    "        representative_runtime = elapsed_time  # Aktualisieren Sie diesen Wert entsprechend\n",
    "        max_allowed_runtime = 1.2 * representative_runtime\n",
    "\n",
    "        # Überprüfen, ob die Laufzeit innerhalb des zulässigen Bereichs liegt\n",
    "        self.assertLessEqual(elapsed_time, max_allowed_runtime)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test des Durchlaufs der Laufzeit von test_fit mit 120% der representativen Zeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Gut gemacht!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
